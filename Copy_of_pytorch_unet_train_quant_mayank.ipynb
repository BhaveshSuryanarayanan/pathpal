{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z97oVb6KbMJa"
   },
   "source": [
    "IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iQKS5yoTyvRH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oKIsD8-BIRiE",
    "outputId": "2bd092fd-20fd-4787-8587-17f19d0cdf15"
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision -f https://storage.googleapis.com/tpu-pytorch/wheels/colab.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQn5KgcmIpl3",
    "outputId": "6af7ed26-34d6-4b87-aa24-86beffa7ee1a"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "\n",
    "# # Check TPU device\n",
    "# device = xm.xla_device()\n",
    "# print(f\"Using TPU: {device}\")\n",
    "\n",
    "# # Run a test operation\n",
    "# x = torch.tensor([1, 2, 3], device=device)\n",
    "# print(f\"Tensor on TPU: {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imFsteVgI5GG",
    "outputId": "b48b0f7d-10cf-40ed-c9a4-97cd441c008f"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch_xla.core.xla_model as xm\n",
    "\n",
    "# device = xm.xla_device()\n",
    "# print(f\"Using TPU: {device}\")\n",
    "\n",
    "# x = torch.tensor([1, 2, 3], device=device)\n",
    "# print(f\"Tensor on TPU: {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzR7DGN30ohs",
    "outputId": "945a0f3c-c951-416a-f45a-fd7595c49f01"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rG66DwqgVZMM",
    "outputId": "2a5e3a42-b9eb-40ca-9d77-d5300c5fcdab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r'C:\\Users\\yagni\\PythonProjects\\Pathpal\\Obstacle Detection\\City_dataset_full'\n",
    "\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "    print(\"The folder exists.\")\n",
    "else:\n",
    "    print(\"The folder does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PcuYbI-hHxc2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "d3HmwuSxa2h_"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NPGZSBs7JMC9"
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "Masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "znOXZxoPNww_"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxiF67tV0L_f",
    "outputId": "15cb976b-6b53-4e1e-ca83-4c8e560ed5fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "DwmvauzgNbng"
   },
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),# Converts the image to a tensor and scales pixel values to [0, 1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "oy5C3zJUjgMW"
   },
   "outputs": [],
   "source": [
    "masks_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x[:1, :, :]),\n",
    "    transforms.Lambda(lambda x : x > 0.04),# Converts the image to a tensor and scales pixel values to [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Wz5Fpuo5lQNg"
   },
   "outputs": [],
   "source": [
    "mask_transform_india= transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "      transforms.Lambda(lambda x: x[:1, :, :]),\n",
    "    transforms.Lambda(lambda x : x > 0.5),# Converts the image to a tensor and scales pixel values to [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qJGWBcKGl8hn"
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "for dirpath, dirnames, filenames in os.walk(r\"C:\\Users\\yagni\\PythonProjects\\Pathpal\\Obstacle Detection\\Indian_road_data\\Indian_road_data\\Raw_images\\train\"):\n",
    "    if k==0:\n",
    "        k=k+1\n",
    "        pass\n",
    "    elif k!=0:\n",
    "        items = os.listdir(dirpath)\n",
    "        for item in items:\n",
    "            img = Image.open(os.path.join(dirpath,item))\n",
    "            train_images.append(transform(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRqi4qM3Eta-",
    "outputId": "1878b2a3-665b-43a9-8773-e8f73d39d0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "YTjRb0S0l-aI"
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "for dirpath, dirnames, filenames in os.walk(r\"C:\\Users\\yagni\\PythonProjects\\Pathpal\\Obstacle Detection\\Indian_road_data\\Indian_road_data\\Masks\\train\"):\n",
    "    if j==0:\n",
    "        j=j+1\n",
    "        pass\n",
    "    elif j!=0:\n",
    "        masks = os.listdir(dirpath)\n",
    "        for mask in masks:\n",
    "            if not mask.endswith('.png'):\n",
    "                continue\n",
    "            img = Image.open(os.path.join(dirpath,mask))\n",
    "            Masks.append(mask_transform_india(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dYAR4j2EwtB",
    "outputId": "0e33b104-7532-4012-c75f-5be15046d78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(Masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "T01PWhxaFDsN"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for dirpath, dirnames, filenames in os.walk(r\"C:\\Users\\yagni\\PythonProjects\\Pathpal\\Obstacle Detection\\City_dataset_full\"):\n",
    "    if dirnames and i==0 :\n",
    "        i=i+1\n",
    "        pass\n",
    "\n",
    "    elif dirnames and i!=0 :\n",
    "        path = os.path.join(dirpath,\"images\")\n",
    "        path_masks= os.path.join(dirpath,\"mask\")\n",
    "        items = os.listdir(path)\n",
    "        masks = os.listdir(path_masks)\n",
    "        count = 0\n",
    "        for item in items:\n",
    "            img = Image.open(os.path.join(path,item))\n",
    "            train_images.append(transform(img))\n",
    "\n",
    "        for mask in masks:\n",
    "            if count % 3 == 1 :\n",
    "                msk = os.path.join(path_masks,mask)\n",
    "                msk = Image.open(msk)\n",
    "                Masks.append(masks_transform(msk))\n",
    "                count =count +1\n",
    "            else :\n",
    "                count= count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvj_0IYYM8PX",
    "outputId": "dbc4ac4a-3974-4e2e-9c85-d2215670f0a4"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(Masks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(train_images[0].shape)\n",
    "print(Masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "c5Ln1koESFv-"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# torch.tensor(train_images,dtype=torch.float32) this method is wrong u cant convert a list of tensors to a tensor u need to use stack\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(Masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# torch.tensor(train_images,dtype=torch.float32) this method is wrong u cant convert a list of tensors to a tensor u need to use stack\n",
    "X_train = torch.stack(train_images, dim =0)\n",
    "y_train = torch.stack(Masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHVdaBbtrfkG"
   },
   "outputs": [],
   "source": [
    "perm = torch.randperm(X_train.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "793AvuknrgfE"
   },
   "outputs": [],
   "source": [
    "X_train_shuffled = X_train[perm]\n",
    "y_train_shuffled = y_train[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcs0L2j9TCOf",
    "outputId": "feb8fad4-39ac-48d7-d748-d8c468305db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3688, 256, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.squeeze(dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJktEg_A3_jR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiSWaageTkhN"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE-PJNAySpOJ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE6UwEEESr50"
   },
   "outputs": [],
   "source": [
    "total_size = len(CustomDataset(X_train,y_train))\n",
    "train_size = int(0.9 * total_size)  # 90% for training\n",
    "val_size = total_size - train_size   # The remaining 10% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsqNcFYzU1sX"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(CustomDataset(X_train,y_train), [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8KYO2a9UjQc"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size= 8 ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVrUl7P5haGR"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_channels,output_channels):\n",
    "   block = nn.Sequential(\n",
    "   nn.Conv2d(in_channels=input_channels,out_channels = output_channels,kernel_size=3,stride=1,padding=1),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(in_channels=output_channels,out_channels = output_channels,kernel_size=3,stride=1,padding=1),\n",
    "   nn.ReLU()\n",
    "   )\n",
    "   return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIpQOgcyZUCw"
   },
   "outputs": [],
   "source": [
    "class Encoder_Block(nn.Module):\n",
    "  def __init__(self,input_channels,output_channels):\n",
    "    super().__init__()\n",
    "    self.conv = conv_block(input_channels,output_channels)\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv(x)\n",
    "    p = self.maxpool(x)\n",
    "    return x ,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JK8xaI4Blg_4"
   },
   "outputs": [],
   "source": [
    "class Decoder_block(nn.Module):\n",
    "\n",
    "  def __init__(self,input_channels,output_channels):\n",
    "    super().__init__()\n",
    "    self.conv_transpose = nn.ConvTranspose2d(input_channels,output_channels,kernel_size=2,stride=2,padding=0)\n",
    "    self.conv = conv_block(input_channels,output_channels)\n",
    "\n",
    "  def forward(self,x,skip_features):\n",
    "    x = self.conv_transpose(x)\n",
    "    x = torch.cat((x,skip_features),dim=1)\n",
    "    x = self.conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fh9_FxnFqvEd"
   },
   "outputs": [],
   "source": [
    "class Encoder_block(nn.Module):\n",
    "\n",
    "  def __init__(self,input_channels,output_channels):\n",
    "    super().__init__()\n",
    "    self.conv = conv_block(input_channels,output_channels)\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv(x)\n",
    "    p = self.maxpool(x)\n",
    "    return x ,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgYxTABEBOia"
   },
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    " def __init__(self):\n",
    "    super().__init__()\n",
    "    self.encoder1 = Encoder_block(3,64)\n",
    "    self.encoder2 = Encoder_block(64,128)\n",
    "    self.encoder3 = Encoder_block(128,256)\n",
    "    self.encoder4 = Encoder_block(256,512)\n",
    "\n",
    "    self.base_layer = conv_block(512,1024)\n",
    "\n",
    "    self.decoder1 = Decoder_block(1024,512)\n",
    "    self.decoder2 = Decoder_block(512,256)\n",
    "    self.decoder3 = Decoder_block(256,128)\n",
    "    self.decoder4 = Decoder_block(128,64)\n",
    "\n",
    "    self.final_layer =nn.Sequential(nn.Conv2d(in_channels=64,out_channels=1,kernel_size=1), nn.Sigmoid())\n",
    "\n",
    " def forward(self,X):\n",
    "\n",
    "      x1, p1 = self.encoder1(X)\n",
    "\n",
    "      x2, p2 = self.encoder2(p1)\n",
    "\n",
    "      x3, p3 = self.encoder3(p2)\n",
    "\n",
    "      x4, p4 = self.encoder4(p3)\n",
    "\n",
    "      base = self.base_layer(p4)\n",
    "\n",
    "      dec1 = self.decoder1(base,x4)\n",
    "\n",
    "      dec2 = self.decoder2(dec1,x3)\n",
    "\n",
    "      dec3 = self.decoder3(dec2,x2)\n",
    "\n",
    "      dec4 = self.decoder4(dec3,x1)\n",
    "\n",
    "      final_output = self.final_layer(dec4)\n",
    "      return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZwsJNRtbWiE"
   },
   "outputs": [],
   "source": [
    "model_testing = UNET().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2eddhP6qiUM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_testing.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "# model_testing = torch.quantization.prepare_qat(model_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Cm-Btb6BkC-"
   },
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHdCKvSEBotP"
   },
   "outputs": [],
   "source": [
    "# loss_func =  nn.BCELoss()\n",
    "optimizer  = torch.optim.Adam(model_testing.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsb1hIRE6EQG"
   },
   "outputs": [],
   "source": [
    "Total_train = (len(train_loader.dataset)*256*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LV-NqV536jXp"
   },
   "outputs": [],
   "source": [
    "Total_val = len(val_loader.dataset)*256*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFLyVbUye2vg"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrjhhe4S0L_j"
   },
   "outputs": [],
   "source": [
    "def dice_calc(prediction_set , truth_set):\n",
    "  accumulator_dice = 0.0\n",
    "  for pred , truth in zip(prediction_set,truth_set):\n",
    "    # A = (pred==1).int().sum()\n",
    "    A = torch.sum(pred==1)\n",
    "    B = torch.sum(truth==1)\n",
    "    C = torch.sum(pred*truth)\n",
    "    accumulator_dice += (C*2/(A+B))\n",
    "  return accumulator_dice/len(prediction_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjmvHJM3luOl"
   },
   "source": [
    "#DICE_LOSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5tOPY3wfoCe"
   },
   "outputs": [],
   "source": [
    "def dice_loss(prediction_set , truth_set):\n",
    "  accumulator_dice = torch.tensor(0.0,device =device)\n",
    "  for pred , truth in zip(prediction_set,truth_set):\n",
    "    A = torch.sum(pred==1).float()\n",
    "    B = torch.sum(truth==1).float()\n",
    "    C = torch.sum(pred*truth).float()\n",
    "    accumulator_dice += (C*2/(A+B))\n",
    "  return 1 - accumulator_dice/len(prediction_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFp5GAqqlydA"
   },
   "source": [
    "tested dice loss its working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydAGB0RwlXSG",
    "outputId": "9466c49d-801f-4149-c6f4-cbe961d537c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "pred = torch.randn(4, 1, 128, 128, requires_grad=True)  # Predictions from the model\n",
    "truth = torch.randint(0, 2, (4, 1, 128, 128)).float()  # Ground truth\n",
    "\n",
    "# Compute Dice loss\n",
    "loss = dice_calc(pred, truth)\n",
    "\n",
    "print(loss.requires_grad)  # Should print True if the loss is part of the computational graph\n",
    "\n",
    "loss.backward()  # Backpropagation should work without errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LF6Gxb5oBiVH",
    "outputId": "c9662baf-8395-482d-e957-cbc278b45747"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.05621312243926234, dice_coefficient: 0.3300883173942566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [02:09<40:54, 129.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 2, Loss: 0.05699332283361377, dice_coefficient: 0.3300895690917969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [04:15<38:16, 127.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 3, Loss: 0.05699473400365951, dice_coefficient: 0.3300887942314148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [06:27<36:39, 129.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 4, Loss: 0.05699100705218911, dice_coefficient: 0.33007484674453735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [08:44<35:18, 132.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 5, Loss: 0.056991956362561956, dice_coefficient: 0.3300900459289551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [11:04<33:48, 135.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 6, Loss: 0.05698776203812372, dice_coefficient: 0.33009618520736694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [13:25<32:02, 137.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 7, Loss: 0.056987600895467026, dice_coefficient: 0.33008500933647156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [15:49<30:11, 139.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 8, Loss: 0.05699185820076975, dice_coefficient: 0.330089271068573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [18:13<28:09, 140.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 9, Loss: 0.05699308481012421, dice_coefficient: 0.3300982117652893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [20:35<25:54, 141.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 10, Loss: 0.05699034116468576, dice_coefficient: 0.3301049768924713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [22:57<23:35, 141.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 11, Loss: 0.05699196106771921, dice_coefficient: 0.33009493350982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [25:18<21:11, 141.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 12, Loss: 0.056993562904385495, dice_coefficient: 0.330093652009964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [27:38<18:46, 140.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 13, Loss: 0.056995481459194364, dice_coefficient: 0.33009493350982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [29:58<16:23, 140.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 14, Loss: 0.05699075753518565, dice_coefficient: 0.33009445667266846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [32:18<14:02, 140.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 15, Loss: 0.05699105063774888, dice_coefficient: 0.3301023244857788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [34:37<11:40, 140.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 16, Loss: 0.056991842127808896, dice_coefficient: 0.3300880491733551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [36:57<09:19, 139.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 17, Loss: 0.056989038087546594, dice_coefficient: 0.3300960659980774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [39:17<06:59, 139.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 18, Loss: 0.056990262883080886, dice_coefficient: 0.33008310198783875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [41:36<04:39, 139.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 19, Loss: 0.05698838759057671, dice_coefficient: 0.33009985089302063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [43:56<02:19, 139.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n",
      "Epoch: 20, Loss: 0.05699246087394662, dice_coefficient: 0.33008500933647156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [46:16<00:00, 138.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.057517673749587724,  Dice Validation 0.32871556282043457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "\n",
    "  model_testing.train()\n",
    "\n",
    "  total_loss = 0.0\n",
    "\n",
    "  dice_total = 0.0\n",
    "  for batch_idx, (data,targets) in enumerate(train_loader):\n",
    "\n",
    "    data , targets = data.to(device), targets.to(device).float()\n",
    "\n",
    "    output = model_testing(data)\n",
    "\n",
    "    loss = dice_loss(output ,targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    pred = (output > 0.5).float()\n",
    "\n",
    "    dice_total += dice_calc(pred,data)\n",
    "\n",
    "  dice_coefficient = dice_total/len(train_loader.dataset)\n",
    "  print(f'Epoch: {epoch}, Loss: {total_loss/len(train_loader.dataset)}, dice_coefficient: {dice_coefficient}')\n",
    "\n",
    "  model_testing.eval()\n",
    "\n",
    "  val_loss = 0.0\n",
    "\n",
    "  dice_val_total = 0\n",
    "\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for batch_idx, (data,targets) in enumerate(val_loader):\n",
    "\n",
    "      data , targets = data.to(device), targets.to(device)\n",
    "\n",
    "      val_output = model_testing(data)\n",
    "\n",
    "      # val_output = val_output.squeeze(dim=1)\n",
    "      loss = dice_loss(val_output,targets.float())\n",
    "\n",
    "      val_loss += loss.item()\n",
    "\n",
    "      pred = (val_output > 0.5)\n",
    "\n",
    "      dice_val_total += dice_calc(pred,data)\n",
    "\n",
    "    dice_coefficient_val = dice_val_total/len(val_loader.dataset)\n",
    "\n",
    "    print(f'Validation Loss: {val_loss/len(val_loader.dataset)},  Dice Validation {dice_coefficient_val}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.08676837773953766, Dice Coefficient: 0.0008464526035822928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [03:43<1:10:38, 223.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08828708489089801, Dice Validation: 0.0\n",
      "Epoch: 2, Loss: 0.08666954779703957, Dice Coefficient: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [07:42<1:09:44, 232.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08828708489089801, Dice Validation: 0.0\n",
      "Epoch: 3, Loss: 0.08666954779703957, Dice Coefficient: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [11:42<1:06:52, 236.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08828708489089801, Dice Validation: 0.0\n",
      "Epoch: 4, Loss: 0.08666954779703957, Dice Coefficient: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [15:46<1:03:45, 239.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08828708489089801, Dice Validation: 0.0\n",
      "Epoch: 5, Loss: 0.08666954779703957, Dice Coefficient: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [19:42<59:33, 238.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08828708489089801, Dice Validation: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BCE Loss Function\n",
    "# def bce_loss(prediction_set, truth_set):\n",
    "#     \"\"\"\n",
    "#     Compute Binary Cross-Entropy loss for a batch of predictions and truths.\n",
    "\n",
    "#     Args:\n",
    "#         prediction_set (torch.Tensor): Predicted logits or probabilities.\n",
    "#         truth_set (torch.Tensor): Ground truth binary labels (0 or 1).\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: Average BCE loss for the batch.\n",
    "#     \"\"\"\n",
    "#     accumulator_bce = 0.0\n",
    "#     for pred, truth in zip(prediction_set, truth_set):\n",
    "#         # Apply sigmoid if `pred` contains raw logits\n",
    "#         pred = torch.sigmoid(pred)\n",
    "#         bce = F.binary_cross_entropy(pred, truth)\n",
    "#         accumulator_bce += bce\n",
    "#     return accumulator_bce / len(prediction_set)\n",
    "loss_func = nn.BCE()\n",
    "# Dice Coefficient Calculation\n",
    "def dice_calc(prediction_set, truth_set):\n",
    "    \"\"\"\n",
    "    Compute the Dice coefficient for predictions and ground truth.\n",
    "\n",
    "    Args:\n",
    "        prediction_set (torch.Tensor): Predicted binary values (0 or 1).\n",
    "        truth_set (torch.Tensor): Ground truth binary values (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Average Dice coefficient for the batch.\n",
    "    \"\"\"\n",
    "    accumulator_dice = 0.0\n",
    "    for pred, truth in zip(prediction_set, truth_set):\n",
    "        A = torch.sum(pred == 1)\n",
    "        B = torch.sum(truth == 1)\n",
    "        C = torch.sum(pred * truth)\n",
    "        accumulator_dice += ((C * 2) / (A + B))\n",
    "    return accumulator_dice / len(prediction_set)\n",
    "\n",
    "# Training Loop with BCE Loss\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "\n",
    "    model_testing.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    dice_total = 0.0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device).float()\n",
    "\n",
    "        output = model_testing(data)  # Raw logits\n",
    "\n",
    "        loss = loss_func(output, targets)  # Compute BCE loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pred = (output > 0.5).float()  # Convert logits to binary\n",
    "        dice_total += dice_calc(pred, targets)\n",
    "\n",
    "    dice_coefficient = dice_total / len(train_loader.dataset)\n",
    "    print(f'Epoch: {epoch}, Loss: {total_loss / len(train_loader.dataset)}, Dice Coefficient: {dice_coefficient}')\n",
    "\n",
    "    # Validation\n",
    "    model_testing.eval()\n",
    "    val_loss = 0.0\n",
    "    dice_val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(val_loader):\n",
    "            data, targets = data.to(device), targets.to(device).float()\n",
    "\n",
    "            val_output = model_testing(data)\n",
    "\n",
    "            loss = loss_func(val_output, targets)  # Compute BCE loss for validation\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            pred = (val_output > 0.5).float()  # Convert logits to binary\n",
    "            dice_val_total += dice_calc(pred, targets)\n",
    "\n",
    "        dice_coefficient_val = dice_val_total / len(val_loader.dataset)\n",
    "        print(f'Validation Loss: {val_loss / len(val_loader.dataset)}, Dice Validation: {dice_coefficient_val}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CYtdkk0QTY6"
   },
   "outputs": [],
   "source": [
    "torch.save(model_testing.state_dict(), \"weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yPkMt_fiEGP"
   },
   "outputs": [],
   "source": [
    "# quantized_model = torch.quantization.convert(model_testing)\n",
    "\n",
    "# # Save the quantized model\n",
    "# torch.save(quantized_model, \"qat_quantized_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Riz4kV4jlgj"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.download('runs/detect/train/weights/last.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
