{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from enum import Enum\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_grid(image):\n",
    "    HEIGHT, WIDTH, CHANNELS = image.shape\n",
    "    one_third_height = HEIGHT // 3\n",
    "    one_third_width = WIDTH // 3\n",
    "    new_image = np.copy(image)\n",
    "    cv2.line(new_image, (one_third_width, 0), (one_third_width, HEIGHT), (0, 0, 0), 5)\n",
    "    cv2.line(new_image, (2 * one_third_width, 0), (2 * one_third_width, HEIGHT), (0, 0, 0), 5)\n",
    "    cv2.line(new_image, (0, one_third_height), (WIDTH, one_third_height), (0, 0, 0), 5)\n",
    "    cv2.line(new_image, (0, 2 * one_third_height), (WIDTH, 2 * one_third_height), (0, 0, 0), 5)\n",
    "    return new_image\n",
    "\n",
    "def vibration_matrix(mask):\n",
    "    HEIGHT, WIDTH = mask.shape\n",
    "    one_third_height = HEIGHT // 3\n",
    "    one_third_width = WIDTH // 3\n",
    "\n",
    "    COUNT_THRESH = (one_third_height * one_third_width) / 5\n",
    "    freq_matrix = np.zeros((3, 3))\n",
    "\n",
    "    output = np.zeros((HEIGHT, WIDTH, 3))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            startx = one_third_width * i\n",
    "            endx = startx + one_third_width\n",
    "            starty = one_third_height * j\n",
    "            endy = starty + one_third_height\n",
    "\n",
    "            box = mask[starty:endy, startx:endx]\n",
    "            freq_matrix[i][j] = np.sum(box == 1)\n",
    "\n",
    "            clr = (0, 255, 0) if freq_matrix[i][j] < COUNT_THRESH else (0, 0, 255)\n",
    "            cv2.rectangle(output, (startx, starty), (endx, endy), clr, thickness=cv2.FILLED)\n",
    "\n",
    "    output = draw_grid(output)\n",
    "    for row in freq_matrix:\n",
    "        print(row)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class ModelType(Enum):\n",
    "    DPT_LARGE = \"DPT_Large\"\n",
    "    DPT_HYBRID = \"DPT_Hybrid\"\n",
    "    MIDAS_SMALL = \"MiDaS_small\"\n",
    "    \n",
    "class Midas():\n",
    "    def __init__(self, modelType: ModelType = ModelType.DPT_LARGE):\n",
    "        self.midas = torch.hub.load(\"isl-org/MiDaS\", modelType.value)\n",
    "        self.modelType = modelType\n",
    "        self.THRESH = 0\n",
    "\n",
    "    def useCUDA(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        self.midas.to(self.device)\n",
    "        self.midas.eval()\n",
    "\n",
    "    def transform(self):\n",
    "        midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "        if self.modelType.value == \"DPT_Large\":\n",
    "            self.transform = midas_transforms.dpt_transform\n",
    "            self.THRESH = 26\n",
    "        elif self.modelType.value == \"DPT_Hybrid\":\n",
    "            self.transform = midas_transforms.dpt_transform\n",
    "            self.THRESH = 1900\n",
    "        else:\n",
    "            self.transform = midas_transforms.small_transform\n",
    "            self.THRESH = 850\n",
    "\n",
    "    def predict(self, frame):\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        input_batch = self.transform(img).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            prediction = self.midas(input_batch)\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                prediction.unsqueeze(1),\n",
    "                size=img.shape[:2],\n",
    "                mode=\"bicubic\",\n",
    "                align_corners=False,\n",
    "            ).squeeze()\n",
    "        depthMap = prediction.cpu().numpy()\n",
    "        return depthMap\n",
    "\n",
    "def process_frame(frame, midasObj):\n",
    "    # Resize the frame to 256x256\n",
    "    frame = cv2.resize(frame, (256, 256))\n",
    "    \n",
    "    # Convert the frame to tensor, permute to match the model's expected input shape\n",
    "    input_image = torch.tensor(frame).float().permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Segmentation prediction\n",
    "    predicted_mask = model(input_image).squeeze(0).cpu().detach().numpy()\n",
    "    predicted_mask = np.uint8((predicted_mask > 0.9) * 255)\n",
    "    \n",
    "    # Ensure mask is 2D by taking the first channel if it's 3D\n",
    "    if len(predicted_mask.shape) == 3:\n",
    "        mask = predicted_mask[0]  # Taking the first channel of the mask\n",
    "    else:\n",
    "        mask = predicted_mask  # If already 2D\n",
    "\n",
    "    # Depth Prediction using MiDaS model\n",
    "    depthMap = midasObj.predict(frame)\n",
    "\n",
    "    # Create a masked depth map only where the segmentation mask is present\n",
    "    masked_depth_map = np.zeros_like(depthMap)\n",
    "    \n",
    "    # Apply the 2D mask to the depth map\n",
    "    masked_depth_map[mask > 0] = depthMap[mask > 0]\n",
    "    \n",
    "    # Threshold based on the depth map's values\n",
    "    mask = masked_depth_map > midasObj.THRESH\n",
    "\n",
    "    # Highlight regions based on the depth threshold (red overlay on frame)\n",
    "    frame[mask] = [255, 0, 0]\n",
    "    \n",
    "    # Generate vibration matrix\n",
    "    output = vibration_matrix(mask.astype(np.uint8))\n",
    "\n",
    "    return frame, output\n",
    "\n",
    "\n",
    "def run_on_webcam(modelType: ModelType):\n",
    "    midasObj = Midas(modelType)\n",
    "    midasObj.useCUDA()\n",
    "    midasObj.transform()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process the frame for segmentation and depth prediction\n",
    "        processed_frame, vibration_output = process_frame(frame, midasObj)\n",
    "\n",
    "        # Display the processed frame and the vibration matrix output\n",
    "        cv2.imshow('Processed Frame', processed_frame)\n",
    "        cv2.imshow('Vibration Matrix', vibration_output)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_on_webcam(ModelType.DPT_HYBRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
